General TODO list for MORSE
---------------------------

==============
 TARGET 0.5
==============

- Fix bug in odometry sensor (Gilberto)

Packaging
---------

- Add package(s) for pymorse

Documentation
-------------

- Add docstrings to all modules (everyone)
- Update the documentation for the human "robot"


Public Relations
----------------

- Fresh screenshots!
- Fresh videos!

==============
 NEXT TARGETS
==============


General
-------

- Support for Blender >= 2.62
[PARTIAL] - Introduce a mean to externally control time, by pacing the game
	engine time (e.g. through a socket, cf mail from Benoit Bolsee on Jan. the 10th
	in blender-robotics). Add support to pause the simulation. Currently, time
	synchronization only implemented in multinode mode.
- Export simulator time + test it
[?] - Fix the physical properties of robot to enable velocity control (cf commit 8503c9)
[?] - define a method to select the control of robots using position or velocity

- Make sure only the camera currently currently active in simulation
    (cameraFP, human, etc.) can be controlled with mouse and keyboard.
    Other cameras should not be affected

- Allow configuring of the Screen object (present by default in all scenes) to
    display the view of the selected camera. Either:
    - Toggle between cameras with a button press
    - Select the chosen camera from the Builder API


Collada
-------

- Import/export of models in Collada 1.5, with kinematics chains.

Middleware
----------

[PARTIAL] - add support for actions through ROS middleware (cf commit 02fda)

- support general mapping of free-function services to any middleware (currently
  works only for free-function services declared for the 'simulation' pseudo-
  component)

Simulation supervision
----------------------

- Introduce means to define scenarios with controlled dynamic events (through
  requests and/or a simple scripting API). Requires a notion of timeline (in
  the API? in the simulator?)

Components
----------

- Motion capture poster: MORSE should be able to simulate a motion capture setup
by allowing the designer to paste markers in the scene whose position will be
exported

[WIP] - Kinect integration: Control of the arms of the human avatar with a Kinect,
using the IK chains in the armature

[WIP] - "Point Cloud" sensors: generate 3D depth images to simulate either
stereovision at an abstract level or various Lidars. Make it generic: export
depth data (openGL z-buffer?), define modifiers that sample the data according
to a given sensor geometry.

- Export position in a consistent way through in different components (use
  Transformation3D)

- PR2: cf TODO.pr2

[PARTIAL] - Support for 4-wheeled vehicles (cf https://github.com/pierriko/morse/tree/experimental_wjwwood)


Documentation
-------------
- Correct documentation for the HRI experiments (current one does not mention the Builder)

- Fix the outdated documentation at http://wiki.blender.org/index.php/Community:Science/Robotics

================
 OTHERS and MISC
================

GUI
---

- Add a GUI for a the scenario configuration -> to be refined to use the Python API for scene creation

Coding style
------------

- every simple function must have a function comment ( """ ... """)
- Change the names of modules, variables, classes, etc. to comply with the
  naming conventions in: http://www.python.org/dev/peps/pep-0008/
- Change the names of objects in .blend file, so that they can be dynamically added using a Python script. Give Specific prefixes to the parent component and other linkable objects

Frame transformations
---------------------

- Representation of all the frames defined within a robot (one frame per sensor,
  one robot frame). 
- Geo-referenced frames for initial geographic data (define and store a frame
  transformation between the Blender reference frame and an abosolute
  geo-reference frame)
- Respect the usual standards (e.g. for cameras), define and document the other
  choices

User-interface
--------------
- Graphic tree of logic components and their interaction (no meshes, ... )

Architecture
------------
- unified time management ("what if we want to simulate at 2X?")

Simulated component
-------------------
- Simulation of wireless communication between robots: delay, lost of connection, noise...

Other stuff 
-----------

- find a way to limit the framerate of the simulation, without lowering the physics clock (only the display).
  This would allow to free CPU for other application while the simulator is running.
- commit policy
